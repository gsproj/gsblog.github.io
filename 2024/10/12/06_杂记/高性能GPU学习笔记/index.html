

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="GongSheng">
  <meta name="keywords" content="">
  
    <meta name="description" content="高性能GPU服务器硬件拓扑和集群组网 转载自：http:&#x2F;&#x2F;arthurchiao.art&#x2F;blog&#x2F;gpu-advanced-notes-1-zh&#x2F;#11-pcie-%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87 感谢原作者的分享！在此基础上改动为个人版本。  1 术语与基础大模型训练一般都是用单机 8 卡 GPU 主机组成集群，机型包括 8*&#123;A100,A8">
<meta property="og:type" content="article">
<meta property="og:title" content="迎风之豚的博客">
<meta property="og:url" content="http://gsproj.github.io/2024/10/12/06_%E6%9D%82%E8%AE%B0/%E9%AB%98%E6%80%A7%E8%83%BDGPU%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="迎风之豚的博客">
<meta property="og:description" content="高性能GPU服务器硬件拓扑和集群组网 转载自：http:&#x2F;&#x2F;arthurchiao.art&#x2F;blog&#x2F;gpu-advanced-notes-1-zh&#x2F;#11-pcie-%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87 感谢原作者的分享！在此基础上改动为个人版本。  1 术语与基础大模型训练一般都是用单机 8 卡 GPU 主机组成集群，机型包括 8*&#123;A100,A8">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012131712609.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012132051768.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012132200770.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012131712609.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012132323761.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012132627792.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012131712609.png">
<meta property="og:image" content="http://gsproj.github.io/img/NVIDIA-DGX-A100-Block-Diagram.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012133420998.png">
<meta property="og:image" content="http://gsproj.github.io/img/a100-idc-network.png">
<meta property="og:image" content="http://gsproj.github.io/img/8x-a100-bw-limits.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012134446643.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012134550723.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012134613017.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012134804131.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012135201064.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012135239994.png">
<meta property="og:image" content="http://gsproj.github.io/img/image-20241012135328084.png">
<meta property="article:published_time" content="2024-10-12T05:15:05.648Z">
<meta property="article:modified_time" content="2024-10-12T07:02:43.846Z">
<meta property="article:author" content="GongSheng">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://gsproj.github.io/img/image-20241012131712609.png">
  
  
  
  <title>迎风之豚的博客</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"gsproj.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Haris的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text=""></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-10-12 13:15" pubdate>
          2024年10月12日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          3.6k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          31 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header"></h1>
            
            
              <div class="markdown-body">
                
                <h1 id="高性能GPU服务器硬件拓扑和集群组网"><a href="#高性能GPU服务器硬件拓扑和集群组网" class="headerlink" title="高性能GPU服务器硬件拓扑和集群组网"></a>高性能GPU服务器硬件拓扑和集群组网</h1><blockquote>
<p>转载自：<a target="_blank" rel="noopener" href="http://arthurchiao.art/blog/gpu-advanced-notes-1-zh/#11-pcie-%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87">http://arthurchiao.art/blog/gpu-advanced-notes-1-zh/#11-pcie-%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87</a></p>
<p>感谢原作者的分享！在此基础上改动为个人版本。</p>
</blockquote>
<h1 id="1-术语与基础"><a href="#1-术语与基础" class="headerlink" title="1 术语与基础"></a>1 术语与基础</h1><p>大模型训练一般都是用单机 8 卡 GPU 主机组成集群，机型包括 <code>8*&#123;A100,A800,H100,H800&#125;</code> 。 下面一台典型 8*A100 GPU 的主机内硬件拓扑：</p>
<p><img src="/../../img/image-20241012131712609.png" srcset="/img/loading.gif" lazyload alt="典型 8 卡 A100 主机硬件拓扑"></p>
<p>本节将基于这张图来介绍一些概念和术语，有基础的可直接跳过。</p>
<h2 id="1-1-PCIe-交换芯片"><a href="#1-1-PCIe-交换芯片" class="headerlink" title="1.1 PCIe 交换芯片"></a>1.1 PCIe 交换芯片</h2><p>CPU、内存、存储（NVME）、GPU、网卡等<strong>支持 PICe 的设备</strong>，都可以连接到 PCIe 总线或专门的 PCIe 交换芯片，实现互联互通。</p>
<p>PCIe 目前有 5 代产品，最新的是 **<code>Gen5</code>**。</p>
<h2 id="1-2-NVLink"><a href="#1-2-NVLink" class="headerlink" title="1.2 NVLink"></a>1.2 <code>NVLink</code></h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>Wikipedia 上 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/NVLink">NVLink</a> 上的定义：</p>
<blockquote>
<p>NVLink is a wire-based serial multi-lane near-range communications link developed by Nvidia. Unlike PCI Express, a device can consist of multiple NVLinks, and devices use mesh networking to communicate instead of a central hub. The protocol was first announced in March 2014 and uses a proprietary high-speed signaling interconnect (NVHS).</p>
</blockquote>
<p>简单总结：同主机内不同 GPU 之间的一种高速互联方式，</p>
<ol>
<li>是一种短距离<strong>通信链路</strong>，保证包的成功传输，更高性能，替代 PCIe，</li>
<li>支持多 lane，link 带宽随 lane 数量线性增长，</li>
<li>同一台 node 内的 GPU 通过 NVLink 以 <strong>full-mesh</strong> 方式（类似 spine-leaf）互联，</li>
<li>NVIDIA 专利技术。</li>
</ol>
<h3 id="演进：1-2-3-4-代"><a href="#演进：1-2-3-4-代" class="headerlink" title="演进：1&#x2F;2&#x2F;3&#x2F;4 代"></a>演进：1&#x2F;2&#x2F;3&#x2F;4 代</h3><p>主要区别是单条 NVLink 链路的 <strong>lane 数量</strong>、每个 <strong>lane 的带宽</strong>（图中给的都是双向带宽）等：</p>
<p><img src="/./../../img/image-20241012132051768.png" srcset="/img/loading.gif" lazyload alt="NVLink 演进。Image from: HotChips 2022 [1]"></p>
<p>例如，</p>
<ul>
<li>A100 是 <strong><code>2 lanes/NVSwitch \* 6 NVSwitch \* 50GB/s/lane= 600GB/s</code></strong> 双向带宽（单向 300GB&#x2F;s）。注意：这是<strong>一个 GPU 到所有 NVSwitch 的总带宽</strong>；</li>
<li>A800 被阉割了 4 条 lane，所以是 <strong><code>8 lane \* 50GB/s/lane = 400GB/s</code></strong> 双向带宽（单向 200GB&#x2F;s）。</li>
</ul>
<h3 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h3><p>基于 DCGM 可以采集到实时 NVLink 带宽：</p>
<p><img src="/./../../img/image-20241012132200770.png" srcset="/img/loading.gif" lazyload alt="Metrics from dcgm-exporter [5]"></p>
<h2 id="1-3-NVSwitch"><a href="#1-3-NVSwitch" class="headerlink" title="1.3 NVSwitch"></a>1.3 <code>NVSwitch</code></h2><p>还是参考下图</p>
<p><img src="/../../img/image-20241012131712609.png" srcset="/img/loading.gif" lazyload alt="典型 8 卡 A100 主机硬件拓扑"></p>
<p>NVSwitch 是 NVIDIA 的一款<strong>交换芯片</strong>，封装在 GPU module 上，并<strong>不是主机外的独立交换机</strong>。</p>
<p>下面是真机图，浪潮的机器，图中 8 个盒子就是 8 片 A100，右边的 6 块超厚散热片下面就是 NVSwitch 芯片：</p>
<p><img src="/./../../img/image-20241012132323761.png" srcset="/img/loading.gif" lazyload alt="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly Side View. Image source: [2]"></p>
<h2 id="1-4-NVLink-Switch"><a href="#1-4-NVLink-Switch" class="headerlink" title="1.4 NVLink Switch"></a>1.4 NVLink Switch</h2><p><strong><code>NVSwitch</code></strong> 听名字像是交换机，但实际上是 GPU module 上的交换芯片，用来<strong>连接同一台主机内的 GPU</strong>。</p>
<p>2022 年，NVIDIA 把这块芯片拿出来真的做成了交换机，叫 <strong><code>NVLink Switch</code></strong> [3]， 用来<strong>跨主机连接 GPU 设备</strong>。</p>
<p>这俩名字很容易让人混淆。</p>
<h2 id="1-5-HBM-High-Bandwidth-Memory"><a href="#1-5-HBM-High-Bandwidth-Memory" class="headerlink" title="1.5 HBM (High Bandwidth Memory)"></a>1.5 HBM (High Bandwidth Memory)</h2><h3 id="由来"><a href="#由来" class="headerlink" title="由来"></a>由来</h3><p>传统上，GPU 显存和普通内存（DDR）一样插在主板上，通过 PCIe 连接到处理器（CPU、GPU）， 因此速度瓶颈在 PCIe，Gen4 是 64GB&#x2F;s，Gen5 是 128GB&#x2F;s。</p>
<p>因此，一些 GPU 厂商（不是只有 NVIDIA 一家这么做）将<strong>将多个 DDR 芯片堆叠之后与 GPU 芯片封装到一起</strong> （后文讲到 H100 时有图），这样每片 GPU 和它自己的显存交互时，就不用再去 PCIe 交换芯片绕一圈，速度最高可以提升一个量级。 这种<strong>“高带宽内存”</strong>（High Bandwidth Memory）缩写就是 HBM。</p>
<blockquote>
<p>现在 CPU 也有用 HBM 的了，比如 <a target="_blank" rel="noopener" href="https://www.intel.com/content/www/us/en/products/details/processors/xeon/max-series.html">Intel Xeon CPU Max Series</a> 就自带了 64GB HBM2e。</p>
</blockquote>
<p>HBM 的市场目前被 SK 海力士和三星等韩国公司垄断。</p>
<h3 id="演进：HBM-1-2-2e-3-3e"><a href="#演进：HBM-1-2-2e-3-3e" class="headerlink" title="演进：HBM 1&#x2F;2&#x2F;2e&#x2F;3&#x2F;3e"></a>演进：HBM 1&#x2F;2&#x2F;2e&#x2F;3&#x2F;3e</h3><p>From wikipedia <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/High_Bandwidth_Memory">HBM</a></p>
<table>
<thead>
<tr>
<th align="left">版本</th>
<th align="left">Bandwidth</th>
<th align="left">Year</th>
<th>GPU</th>
</tr>
</thead>
<tbody><tr>
<td align="left">HBM</td>
<td align="left">128GB&#x2F;s&#x2F;package</td>
<td align="left"></td>
<td></td>
</tr>
<tr>
<td align="left">HBM2</td>
<td align="left">256GB&#x2F;s&#x2F;package</td>
<td align="left">2016</td>
<td>V100</td>
</tr>
<tr>
<td align="left">HBM2e</td>
<td align="left">~450GB&#x2F;s</td>
<td align="left">2018</td>
<td><code>A100, ~2TB/s</code>; 华为 <code>Ascend 910B</code></td>
</tr>
<tr>
<td align="left">HBM3</td>
<td align="left">600GB&#x2F;s&#x2F;site</td>
<td align="left">2020</td>
<td>H100, 3.35TB&#x2F;s</td>
</tr>
<tr>
<td align="left">HBM3e</td>
<td align="left">~1TB&#x2F;s</td>
<td align="left">2023</td>
<td><code>H200</code>, <a target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/data-center/h200/">4.8TB&#x2F;s</a></td>
</tr>
</tbody></table>
<p><img src="/./../../img/image-20241012132627792.png" srcset="/img/loading.gif" lazyload alt="使用了 HBM 的近几代高端 NVIDIA GPU 显存带宽（双向），纵坐标是 TB/s。Image source: [3]"></p>
<ul>
<li>AMD MI300X 采用 192GB HBM3 方案，带宽 **<code>5.2TB/s</code>**；</li>
<li>HBM3e 是 HBM3 的增强版，速度从 6.4GT&#x2F;s 到 8GT&#x2F;s。</li>
</ul>
<h2 id="1-6-带宽单位"><a href="#1-6-带宽单位" class="headerlink" title="1.6 带宽单位"></a>1.6 带宽单位</h2><p>大规模 GPU 训练的性能与数据传输速度有直接关系。这里面涉及到很多链路，比如 PCIe 带宽、内存带宽、NVLink 带宽、HBM 带宽、网络带宽等等。</p>
<ul>
<li>网络习惯用 <strong><code>bits/second (b/s)</code></strong> 表示之外，并且一般说的都是<strong>单向</strong>（TX&#x2F;RX）；</li>
<li>其他模块带宽基本用 <code>byte/sedond (B/s)</code> 或 <code>transactions/second (T/s)</code> 表示，并且一般都是<strong>双向总带宽</strong>。</li>
</ul>
<p>比较带宽时注意区分和转换。</p>
<h1 id="2-典型-8-A100-8-A800-主机"><a href="#2-典型-8-A100-8-A800-主机" class="headerlink" title="2 典型 8*A100/8*A800 主机"></a>2 典型 <code>8*A100/8*A800</code> 主机</h1><h2 id="2-1-主机内拓扑：2-2-4-6-8-8"><a href="#2-1-主机内拓扑：2-2-4-6-8-8" class="headerlink" title="2.1 主机内拓扑：2-2-4-6-8-8"></a>2.1 主机内拓扑：<code>2-2-4-6-8-8</code></h2><ul>
<li>2 片 CPU（及两边的内存，NUMA）</li>
<li>2 张<strong>存储网卡</strong>（<strong>访问分布式存储</strong>，带内管理等）</li>
<li>4 个 PCIe Gen4 Switch 芯片</li>
<li>6 个 NVSwitch 芯片</li>
<li>8 个 GPU</li>
<li>8 个 <strong>GPU 专属网卡</strong></li>
</ul>
<p><img src="/../../img/image-20241012131712609.png" srcset="/img/loading.gif" lazyload alt="典型 8 卡 A100 主机硬件拓扑"></p>
<p>下面这个图画的更专业，需要更多细节的可参考：</p>
<p><img src="/./../../img/NVIDIA-DGX-A100-Block-Diagram.png" srcset="/img/loading.gif" lazyload alt="NVIDIA DGX A100 主机（官方 8 卡机器）硬件拓扑"></p>
<h3 id="存储网卡"><a href="#存储网卡" class="headerlink" title="存储网卡"></a>存储网卡</h3><p>通过 PCIe <strong>直连 CPU</strong>。用途：</p>
<ol>
<li>从分布式存储读写数据，例如<strong>读训练数据</strong>、<strong>写 checkpoint</strong> 等；</li>
<li>正常的 node 管理，ssh，监控采集等等。</li>
</ol>
<p>官方推荐用 BF3 DPU。但其实只要带宽达标，用什么都行。组网经济点的话用 RoCE，追求最好的性能用 IB。</p>
<h3 id="NVSwitch-fabric：intra-node-full-mesh"><a href="#NVSwitch-fabric：intra-node-full-mesh" class="headerlink" title="NVSwitch fabric：intra-node full-mesh"></a>NVSwitch fabric：intra-node full-mesh</h3><p>8 个 GPU 通过 6 个 NVSwitch 芯片 full-mesh 连接，这个 full-mesh 也叫 <strong><code>NVSwitch fabric</code><strong>； full-mesh 里面的</strong>每根线的带宽是 n * bw-per-nvlink-lane</strong>，</p>
<ul>
<li>A100 用的 NVLink3，**<code>50GB/s/lane</code>**，所以 full-mesh 里的每条线就是 **<code>12\*50GB/s=600GB/s</code>**，注意这个是双向带宽，单向只有 300GB&#x2F;s。</li>
<li>A800 是阉割版，<strong>12 lane 变成 8 lane</strong>，所以每条线 8*50GB&#x2F;s&#x3D;400GB&#x2F;s，单向 200GB&#x2F;s。</li>
</ul>
<h3 id="用-nvidia-smi-topo-查看拓扑"><a href="#用-nvidia-smi-topo-查看拓扑" class="headerlink" title="用 nvidia-smi topo 查看拓扑"></a>用 <code>nvidia-smi topo</code> 查看拓扑</h3><p>下面是一台 8*A800 机器上 <strong><code>nvidia-smi</code></strong> 显示的实际拓扑（网卡两两做了 bond，NIC 0~3 都是 bond）：</p>
<p><img src="/./../../img/image-20241012133420998.png" srcset="/img/loading.gif" lazyload alt="image-20241012133420998"></p>
<ul>
<li>GPU 之间（左上角区域）：都是 **<code>NV8</code>**，表示 <strong>8 条 NVLink</strong> 连接；</li>
<li>NIC 之间：<ul>
<li>在同一片 CPU 上：**<code>NODE</code><strong>，表示</strong>不需要跨 NUMA，但需要跨 PCIe 交换芯片**；</li>
<li>不在同一片 CPU 上：**<code>SYS</code><strong>，表示</strong>需要跨 NUMA**；</li>
</ul>
</li>
<li>GPU 和 NIC 之间：<ul>
<li>在同一片 CPU 上，且在同一个 PCIe Switch 芯片下面：**<code>PXB</code><strong>，表示</strong>只需要跨 PCIe 交换芯片**；</li>
<li>在同一片 CPU 上，且不在同一个 PCIe Switch 芯片下面：**<code>NODE</code><strong>，表示</strong>需要跨 PCIe 交换芯片和 PCIe Host Bridge**；</li>
<li>不在同一片 CPU 上：**<code>SYS</code><strong>，表示</strong>需要跨 NUMA、PCIe 交换芯片，距离最远**；</li>
</ul>
</li>
</ul>
<h2 id="2-2-GPU-训练集群组网：IDC-GPU-fabirc"><a href="#2-2-GPU-训练集群组网：IDC-GPU-fabirc" class="headerlink" title="2.2 GPU 训练集群组网：IDC GPU fabirc"></a>2.2 GPU 训练集群组网：IDC GPU fabirc</h2><p>GPU node 互联架构：</p>
<p><img src="/./../../img/a100-idc-network.png" srcset="/img/loading.gif" lazyload alt="a100-idc-network"></p>
<h3 id="计算网络"><a href="#计算网络" class="headerlink" title="计算网络"></a>计算网络</h3><p>GPU 网卡直连到置顶交换机（leaf），leaf 通过 full-mesh 连接到 spine，形成跨主机 GPU 计算网络。</p>
<ul>
<li>这个网络的目的是 GPU 与其他 node 的 GPU <strong>交换数据</strong>；</li>
<li>每个 GPU 和自己的网卡之间通过 <strong>PCIe 交换芯片连接</strong>：<code>GPU &lt;--&gt; PCIe Switch &lt;--&gt; NIC</code>。</li>
</ul>
<h3 id="存储网络"><a href="#存储网络" class="headerlink" title="存储网络"></a>存储网络</h3><p>直连 CPU 的两张网卡，连接到另一张网络里，主要作用是读写数据，以及 SSH 管理等等。</p>
<h3 id="RoCE-vs-InfiniBand"><a href="#RoCE-vs-InfiniBand" class="headerlink" title="RoCE vs. InfiniBand"></a>RoCE vs. InfiniBand</h3><p>不管是计算网络还是存储网络，都需要 RDMA 才能实现 AI 所需的高性能。RDMA 目前有两种选择：</p>
<ul>
<li>RoCEv2：公有云卖的 8 卡 GPU 主机基本都是这种网络，比如 CX6 <strong><code>8\*100Gbps</code></strong> 配置；在性能达标的前提下，（相对）便宜；</li>
<li>InfiniBand (IB)：同等网卡带宽下，性能比 RoCEv2 好 20% 以上，但是价格贵一倍。</li>
</ul>
<h2 id="2-3-数据链路带宽瓶颈分析"><a href="#2-3-数据链路带宽瓶颈分析" class="headerlink" title="2.3 数据链路带宽瓶颈分析"></a>2.3 数据链路带宽瓶颈分析</h2><p><img src="/./../../img/8x-a100-bw-limits.png" srcset="/img/loading.gif" lazyload alt="单机 8 卡 A100 GPU 主机带宽瓶颈分析"></p>
<p>几个关键链路带宽都标在图上了，</p>
<ol>
<li><p>同主机 GPU 之间：走 NVLink，双向 600GB&#x2F;s，单向 **<code>300GB/s</code>**；</p>
</li>
<li><p>同主机 GPU 和自己的网卡之间：走 PICe Gen4 Switch 芯片，双向 64GB&#x2F;s，单向 **<code>32GB/s</code>**；</p>
</li>
<li><p>跨主机 GPU 之间：需要通过网卡收发数据，这个就看网卡带宽了，目前国内 A100&#x2F;A800 机型配套的主流带宽是（单向） **<code>100Gbps=12.5GB/s</code>**。 所以跨机通信相比主机内通信性能要下降很多。</p>
<ul>
<li><code>200Gbps==25GB/s</code>：已经<strong>接近</strong> PCIe Gen4 的单向带宽；</li>
<li><code>400Gbps==50GB/s</code>：已经<strong>超过</strong> PCIe Gen4 的单向带宽。</li>
</ul>
<p>所以在这种机型里用 400Gbps 网卡作用不大，400Gbps 需要 PCIe Gen5 性能才能发挥出来。</p>
</li>
</ol>
<h1 id="3-典型-8-H100-8-H800-主机"><a href="#3-典型-8-H100-8-H800-主机" class="headerlink" title="3 典型 8*H100/8*H800 主机"></a>3 典型 <code>8*H100/8*H800</code> 主机</h1><p>GPU Board Form Factor 分为两种类型：</p>
<ul>
<li>PCIe Gen5</li>
<li>SXM5：性能更高一些</li>
</ul>
<h2 id="3-1-H100-芯片-layout"><a href="#3-1-H100-芯片-layout" class="headerlink" title="3.1 H100 芯片 layout"></a>3.1 H100 芯片 layout</h2><p>下面是一片 H100 GPU 芯片的内部结构：</p>
<p><img src="/./../../img/image-20241012134446643.png" srcset="/img/loading.gif" lazyload alt="单片H100GPU内部逻辑布局"></p>
<ul>
<li><strong><code>4nm</code></strong> 工艺；</li>
<li>最下面一排是 18 根 Gen4 NVLink；双向总带宽 **<code>18 lanes \* 50GB/s/lane = 900GB/s</code>**；</li>
<li>中间蓝色的是 L2 cache；</li>
<li>左右两侧是 <strong><code>HBM</code></strong> 芯片，即显存；</li>
</ul>
<h2 id="3-2-主机内硬件拓扑"><a href="#3-2-主机内硬件拓扑" class="headerlink" title="3.2 主机内硬件拓扑"></a>3.2 主机内硬件拓扑</h2><p>跟 A100 8 卡机结构大致类似，区别：</p>
<ol>
<li>NVSwitch 芯片从 6 个减少到了 4 个；真机图如下，</li>
</ol>
<p><img src="/./../../img/image-20241012134550723.png" srcset="/img/loading.gif" lazyload alt="A100-8卡真机图"></p>
<p>2.与 CPU 的互联从 PCIe Gen4 x16 升级到 **<code>PCIe Gen5 x16</code>**，双向带宽 **<code>128GB/s</code>**；</p>
<p><img src="/./../../img/image-20241012134613017.png" srcset="/img/loading.gif" lazyload alt="image-20241012134613017"></p>
<h2 id="3-3-组网"><a href="#3-3-组网" class="headerlink" title="3.3 组网"></a>3.3 组网</h2><p>与 A100 也类似，只是标配改成了 <strong><code>400Gbps</code></strong> 的 CX7 网卡， 否则网络带宽与 PCIe Switch 和 NVLink&#x2F;NVSwitch 之间的差距更大了。</p>
<h1 id="4-典型-4-L40S-8-L40S-主机"><a href="#4-典型-4-L40S-8-L40S-主机" class="headerlink" title="4 典型 4*L40S/8*L40S 主机"></a>4 典型 <code>4*L40S/8*L40S</code> 主机</h1><p>L40S 是今年（2023）即将上市的新一代“性价比款”多功能 GPU，<strong>对标 A100</strong>。 除了不适合训练基座大模型之外（后面会看到为什么），官方的宣传里它几乎什么都能干。 <del>价格的话，目前第三方服务器厂商给到的口头报价都是 A100 的 8 折左右</del>。</p>
<h2 id="4-1-L40S-vs-A100-配置及特点对比"><a href="#4-1-L40S-vs-A100-配置及特点对比" class="headerlink" title="4.1 L40S vs A100 配置及特点对比"></a>4.1 L40S vs A100 配置及特点对比</h2><p>L40S 最大的特点之一是 <strong>time-to-market 时间短</strong>，也就是从订货到拿到货周期比 A100&#x2F;A800&#x2F;H800 快很多。 这里面技术和非技术原因都有，比如：</p>
<ul>
<li><del>不存在被美国禁售的功能</del>（根据 2023.10 的新规定，已经禁售了），比如 <strong>FP64 和 NVLink 都干掉了</strong>；</li>
<li>使用 <strong><code>GDDR6</code></strong> 显存，不依赖 HBM 产能（及先进封装）；</li>
</ul>
<p>价格便宜也有几方面原因，后面会详细介绍：</p>
<ol>
<li>大头可能来自 GPU 本身价格降低：因为去掉了一些模块和功能，或者用便宜的产品替代；</li>
<li>整机成本也有节省：例如去掉了一层 PCIe Gen4 Swtich；不过相比于 4x&#x2F;8x GPU，整机的其他部分都可以说送的了；</li>
</ol>
<h2 id="4-2-L40S-与-A100-性能对比"><a href="#4-2-L40S-与-A100-性能对比" class="headerlink" title="4.2 L40S 与 A100 性能对比"></a>4.2 L40S 与 A100 性能对比</h2><p>下面是一个官方标称性能对比：</p>
<p><img src="/./../../img/image-20241012134804131.png" srcset="/img/loading.gif" lazyload alt="L40S与A100性能对比"></p>
<p>具体场景的性能对比网上也有很多官方资料，这里就不列举了。简单来，</p>
<ul>
<li>性能 1.2x ~ 2x（看具体场景）。</li>
<li>功耗：两台 L40S 和单台 A100 差不多</li>
</ul>
<p>需要注意，<strong>L40S 主机官方推荐的是单机 4 卡而不是 8 卡</strong>（后面会介绍为什么）， 所以对比一般是用 <code>两台 4*L40S</code> vs <code>单台 8*A100</code>。另外，很多场景的性能提升有个 <strong>大前提</strong>：网络需要是 200Gbps RoCE 或 IB 网络，接下来介绍为什么。</p>
<h2 id="4-3-L40S-攒机"><a href="#4-3-L40S-攒机" class="headerlink" title="4.3 L40S 攒机"></a>4.3 L40S 攒机</h2><h3 id="推荐架构：2-2-4"><a href="#推荐架构：2-2-4" class="headerlink" title="推荐架构：2-2-4"></a>推荐架构：<code>2-2-4</code></h3><p>相比于 A100 的 <strong><code>2-2-4-6-8-8</code></strong> 架构， 官方推荐的 L40S GPU 主机是 2-2-4 架构，一台机器物理拓扑如下：</p>
<p><img src="/./../../img/image-20241012135201064.png" srcset="/img/loading.gif" lazyload alt="单机4卡L40S GPU"></p>
<p>最明显的变化是<strong>去掉了 CPU 和 GPU 之间的 PCIe Switch 芯片</strong>， 网卡和 GPU 都是直连 CPU 上自带的 PCIe Gen4 x16（64GB&#x2F;s），</p>
<ul>
<li>2 片 CPU（NUMA）</li>
<li>2 张双口 CX7 网卡（每张网卡 **<code>2\*200Gbps</code>**）</li>
<li>4 片 L40S GPU</li>
<li>另外，存储网卡只配 1 张（双口），直连在任意一片 CPU 上</li>
</ul>
<p>这样<strong>每片 GPU 平均 200Gbps 网络带宽</strong>。</p>
<h3 id="不推荐架构：2-2-8"><a href="#不推荐架构：2-2-8" class="headerlink" title="不推荐架构：2-2-8"></a>不推荐架构：<code>2-2-8</code></h3><p><img src="/./../../img/image-20241012135239994.png" srcset="/img/loading.gif" lazyload alt="单机 8 卡 L40S GPU 主机拓扑，来自 NVIDIA L40S 官方推介材料"></p>
<p>如图，跟单机 4 卡相比，单机 8 卡需要引入两片 PCIe Gen5 Switch 芯片：</p>
<ul>
<li>说是现在<strong>PCIe Gen5 Switch 单片价格 1w 刀</strong>（不知真假），一台机器需要 2 片；价格不划算；</li>
<li>PCIe switch 只有一家在生产，产能受限，周期很长；</li>
<li>平摊到每片 GPU 的网络带宽减半；</li>
</ul>
<h2 id="4-4-组网"><a href="#4-4-组网" class="headerlink" title="4.4 组网"></a>4.4 组网</h2><p>官方建议 4 卡机型，搭配 200Gbps RoCE&#x2F;IB 组网。</p>
<h2 id="4-5-数据链路带宽瓶颈分析"><a href="#4-5-数据链路带宽瓶颈分析" class="headerlink" title="4.5 数据链路带宽瓶颈分析"></a>4.5 数据链路带宽瓶颈分析</h2><p><img src="/./../../img/image-20241012135328084.png" srcset="/img/loading.gif" lazyload alt="单机 4 卡 L40S GPU 主机带宽瓶颈分析"></p>
<p>以同 CPU 下面的两种 L40S 为例，这里面有两条链路可选：</p>
<ol>
<li>直接通过 CPU 处理：<code>GPU0 &lt;--PCIe--&gt; CPU &lt;--PCIe--&gt; GPU1</code><ul>
<li>PCIe Gen4 x16 双向 64GB&#x2F;s，单向 **<code>32GB/s</code>**；</li>
<li><strong>CPU 处理瓶颈？TODO</strong></li>
</ul>
</li>
<li>完全绕过 CPU 处理，<strong>通过网卡去外面绕一圈再回来</strong>：<code>GPU0 &lt;--PCIe--&gt; NIC &lt;-- RoCe/IB Switch --&gt; NIC &lt;--PCIe--&gt; GPU1</code><ul>
<li>PCIe Gen4 x16 双向 64GB&#x2F;s，单向 **<code>32GB/s</code>**；</li>
<li>平均每个 GPU 一个单向 200Gbps 网口，单向折算 **<code>25GB/s</code>**；</li>
<li><strong>需要 NCCL 支持</strong>，官方说新版本 NCCL 正在针对 L40S 适配，默认行为就是去外面绕一圈回来；</li>
</ul>
</li>
</ol>
<p>第二种方式看着长了很多，但官方说其实比方式一还要快很多（这里还每太搞懂，CPU 那里是怎么处理的？）—— <strong>前提是网卡和交换机配到位</strong>：200Gbps RoCE&#x2F;IB 网络。在这种网络架构下（网络带宽充足），</p>
<ul>
<li><strong>任何两片 GPU 的通信带宽和延迟都是一样的</strong>，是否在一台机器内或一片 CPU 下面并不重要，集群可以<strong>横向扩展</strong>（scaling up，compared with scaling in）；</li>
<li>GPU 机器成本降低；但其实对于那些对网络带宽要求没那么高的业务来说，是<strong>把 NVLINK 的成本转嫁给了网络</strong>，这时候必须要组建 200Gbps 网络，否则发挥不出 L40S 多卡训练的性能。</li>
</ul>
<p>如果是方式二，同主机内 GPU 卡间的带宽瓶颈在网卡速度。即使网络是推荐的 2*CX7 配置，</p>
<ul>
<li>L40S： 200Gbps（网卡单向线速）</li>
<li>A100： 300GB&#x2F;s（NVLINK3 单向） &#x3D;&#x3D; **<code>12x</code>**200Gbps</li>
<li>A800： 200GB&#x2F;s（NVLINK3 单向） &#x3D;&#x3D; **<code>8x</code>**200Gbps</li>
</ul>
<p>可以看到，<strong>L40S 卡间带宽还是比 A100 NVLINK 慢了 12 倍</strong>， 比 A800 NVLink 慢了 8 倍，所以<strong>不适合数据密集交互的基础大模型训练</strong>。</p>
<h2 id="4-6-测试注意事项"><a href="#4-6-测试注意事项" class="headerlink" title="4.6 测试注意事项"></a>4.6 测试注意事项</h2><p>如上，即便只测试单机 4 卡 L40S 机器，也需要搭配 200Gbps 交换机，否则卡间性能发挥不出来。</p>
<h1 id="5-典型-8-H20-GPU-服务器（2024-更新）"><a href="#5-典型-8-H20-GPU-服务器（2024-更新）" class="headerlink" title="5 典型 8*H20 GPU 服务器（2024 更新）"></a>5 典型 <code>8*H20</code> GPU 服务器（2024 更新）</h1><p>H20 是 2023 年发布，2024 年正式开始交付的 GPU。面向中国大陆市场，填补 A800&#x2F;L40S 等等被禁之后的产品空缺。</p>
<h2 id="5-1-显存：-8-96GB"><a href="#5-1-显存：-8-96GB" class="headerlink" title="5.1 显存：**8\*96GB**"></a>5.1 显存：**<code>8\*96GB</code>**</h2><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">$ nvidia-smi
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.161.03             Driver Version: 535.161.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage&#x2F;Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|
|   0  NVIDIA H20                     On  | 00000000:04:00.0 Off |                    0 |
| N&#x2F;A   24C    P0              72W &#x2F; 500W |      0MiB &#x2F; 97871MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H20                     On  | 00000000:23:00.0 Off |                    0 |
| N&#x2F;A   24C    P0              71W &#x2F; 500W |      0MiB &#x2F; 97871MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
...
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H20                     On  | 00000000:E4:00.0 Off |                    0 |
| N&#x2F;A   24C    P0              72W &#x2F; 500W |      0MiB &#x2F; 97871MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+</code></pre></div></figure>

<p>GPU 最大功耗 <code>8*500W</code>。</p>
<h2 id="5-2-卡间互联：NVLINK-x18-lanes-900GB-s"><a href="#5-2-卡间互联：NVLINK-x18-lanes-900GB-s" class="headerlink" title="5.2 卡间互联：NVLINK x18 lanes = 900GB/s"></a>5.2 卡间互联：NVLINK <code>x18 lanes = 900GB/s</code></h2><figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">$ nvidia-smi topo -m
        GPU0    GPU1    GPU2    GPU3    GPU4    GPU5    GPU6    GPU7    NIC0    NIC1    CPU Affinity    NUMA Affinity   GPU NUMA ID
GPU0     X      NV18    NV18    NV18    NV18    NV18    NV18    NV18    SYS     SYS     0-95,192-287    0               N&#x2F;A
GPU1    NV18     X      NV18    NV18    NV18    NV18    NV18    NV18    SYS     SYS     0-95,192-287    0               N&#x2F;A
GPU2    NV18    NV18     X      NV18    NV18    NV18    NV18    NV18    SYS     SYS     0-95,192-287    0               N&#x2F;A
GPU3    NV18    NV18    NV18     X      NV18    NV18    NV18    NV18    SYS     SYS     0-95,192-287    0               N&#x2F;A
GPU4    NV18    NV18    NV18    NV18     X      NV18    NV18    NV18    NODE    NODE    96-191,288-383  1               N&#x2F;A
GPU5    NV18    NV18    NV18    NV18    NV18     X      NV18    NV18    NODE    NODE    96-191,288-383  1               N&#x2F;A
GPU6    NV18    NV18    NV18    NV18    NV18    NV18     X      NV18    PHB     PHB     96-191,288-383  1               N&#x2F;A
GPU7    NV18    NV18    NV18    NV18    NV18    NV18    NV18     X      NODE    NODE    96-191,288-383  1               N&#x2F;A
NIC0    SYS     SYS     SYS     SYS     NODE    NODE    PHB     NODE     X      PIX
NIC1    SYS     SYS     SYS     SYS     NODE    NODE    PHB     NODE    PIX      X</code></pre></div></figure>

<p>可以看到双向 **<code>18 lanes \* 50GB/s/lane= 900GB/s</code>**（单向 450GB&#x2F;s）。 作为对比，<code>8*A800</code> NVLINK 是 8 lanes，见前面章节。</p>
<h2 id="5-3-网络"><a href="#5-3-网络" class="headerlink" title="5.3 网络"></a>5.3 网络</h2><p>这个看各服务器厂商怎么配了。下面是国内某家的 PCIe 和网卡信息：</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">$ lspci
00:00.0 Host bridge: Advanced Micro Devices, Inc. [AMD] Device 14a4 (rev 01)
c0:00.2 IOMMU: Advanced Micro Devices, Inc. [AMD] Device 149e (rev 01)
c0:01.1 PCI bridge: Advanced Micro Devices, Inc. [AMD] Device 14ab (rev 01)
c1:00.0 PCI bridge: Broadcom &#x2F; LSI PEX890xx PCIe Gen 5 Switch (rev b0)           # &lt;-- PCIe Gen5
c2:00.0 PCI bridge: Broadcom &#x2F; LSI PEX890xx PCIe Gen 5 Switch (rev b0)
c3:00.0 3D controller: NVIDIA Corporation Device 2329 (rev a1)
c6:00.0 Ethernet controller: Mellanox Technologies MT2894 Family [ConnectX-6 Lx] # &lt;-- Mellanox CX6
c6:00.1 Ethernet controller: Mellanox Technologies MT2894 Family [ConnectX-6 Lx]
...</code></pre></div></figure>

<p>RDMA：</p>
<figure><div class="code-wrapper"><pre class="line-numbers language-none"><code class="language-none">$ ibstat
CA &#39;mlx5_0&#39;
        CA type: MT4127
        Number of ports: 1
        Port 1:
                State: Down
                Physical state: Disabled
                Rate: 40
                Base lid: 0
                LMC: 0
                SM lid: 0
                Capability mask: 0x00010000
                Link layer: Ethernet
CA &#39;mlx5_1&#39;
        CA type: MT4127
        Number of ports: 1
        Port 1:
                State: Down
                Physical state: Disabled
                Rate: 40
                Base lid: 0
                LMC: 0
                SM lid: 0
                Capability mask: 0x00010000
                Link layer: Ethernet</code></pre></div></figure>



<h2 id="5-4-训练性能：8-H20-vs-8-A800"><a href="#5-4-训练性能：8-H20-vs-8-A800" class="headerlink" title="5.4 训练性能：8*H20 vs 8*A800"></a>5.4 训练性能：<code>8*H20 vs 8*A800</code></h2><p>单机 8 卡训练性能（实测数据，但大家用的模型、框架、数据集等可能各不相同，因此这里的结果仅供参考）：</p>
<table>
<thead>
<tr>
<th align="left">GPU Node (NVLINK interconnect)</th>
<th align="left">Throughput</th>
</tr>
</thead>
<tbody><tr>
<td align="left">8*A800-80GB</td>
<td align="left"><strong><code>~30</code></strong> samples&#x2F;sec</td>
</tr>
<tr>
<td align="left"><strong><code>8\*H20-96GB</code></strong></td>
<td align="left"><strong><code>~21</code></strong> samples&#x2F;sec</td>
</tr>
</tbody></table>
<p>相比 A800，H20 纸面算力阉割了一半左右 [6]，但在 NVLINK&#x2F;cache 等地方补了一下，所以实际性能（只）下降了 1&#x2F;3。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol>
<li><a target="_blank" rel="noopener" href="https://hc34.hotchips.org/">NVLink-Network Switch - NVIDIA’s Switch Chip for High Communication-Bandwidth SuperPODs</a>, Hot Chips 2022</li>
<li><a target="_blank" rel="noopener" href="https://www.servethehome.com/chatgpt-hardware-a-look-at-8x-nvidia-a100-systems-powering-the-tool-openai-microsoft-azure-supermicro-inspur-asus-dell-gigabyte/">ChatGPT Hardware a Look at 8x NVIDIA A100 Powering the Tool</a>, 2023</li>
<li><a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">NVIDIA Hopper Architecture In-Depth</a>, nvidia.com, 2022</li>
<li><a target="_blank" rel="noopener" href="https://www.microway.com/hpc-tech-tips/dgx-a100-review-throughput-and-hardware-summary/">DGX A100 review: Throughput and Hardware Summary</a>, 2020</li>
<li><a target="_blank" rel="noopener" href="http://arthurchiao.art/blog/understanding-gpu-performance/">Understanding NVIDIA GPU Performance: Utilization vs. Saturation</a>, 2023</li>
<li><a target="_blank" rel="noopener" href="http://arthurchiao.art/blog/gpu-data-sheets/">GPU Performance (Data Sheets) Quick Reference (2023)</a></li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div></div>
      <div>http://gsproj.github.io/2024/10/12/06_杂记/高性能GPU学习笔记/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>GongSheng</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年10月12日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/09/09/06_%E6%9D%82%E8%AE%B0/Mellanox%E7%BD%91%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8/" title="Mellanox网卡安装驱动">
                        <span class="hidden-mobile">Mellanox网卡安装驱动</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script  src="https://lib.baomitu.com/prism/1.29.0/components/prism-core.min.js" ></script>

  <script  src="https://lib.baomitu.com/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" ></script>

  <script  src="https://lib.baomitu.com/prism/1.29.0/plugins/line-numbers/prism-line-numbers.min.js" ></script>

  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
